import streamlit as st
import numpy as np
import pandas as pd
import re
from nltk.corpus import stopwords
from nltk.stem.porter import PorterStemmer
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import accuracy_score



# Load data
news_df = pd.read_csv('train.csv.zip')

# Handle missing values
news_df = news_df.fillna('')

# Combine relevant columns to create 'content'
news_df['content'] = news_df['author'] + ' ' + news_df['title']

# Initialize stemmer
ps = PorterStemmer()

def stemming(content):
    stemmed_content = re.sub('[^a-zA-Z]', ' ', content)
    stemmed_content = stemmed_content.lower()
    stemmed_content = stemmed_content.split()
    stemmed_content = [ps.stem(word) for word in stemmed_content if word not in stopwords.words('english')]
    return ' '.join(stemmed_content)

# Apply stemming to content
news_df['content'] = news_df['content'].apply(stemming)

# Prepare features and labels
X = news_df['content']
y = news_df['label']

# Vectorization
vectorizer = TfidfVectorizer()
X = vectorizer.fit_transform(X)

# Split data
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y, random_state=1)

# Train model
model = LogisticRegression()
model.fit(X_train, y_train)

# Streamlit app
st.title('Fake News Detector')

# Text input with proper Streamlit method
input_text = st.text_input('Enter News Article')

# Prediction functionality
if input_text:
    # Preprocess input
    processed_text = stemming(input_text)
    vectorized_text = vectorizer.transform([processed_text])
    
    # Make prediction
    prediction = model.predict(vectorized_text)
    
    # Display result
    st.subheader('Prediction:')
    if prediction[0] == 0:
        st.success('✅ This news appears to be genuine')
    else:
        st.error('❌ This news appears to be fake')
